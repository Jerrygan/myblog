### 1.kafak定位offset消息数据 ==间接寻址、二分查找

kafka的分片+索引机制，每个分区（partition分区有序）分为多个segment 对应着两个文件

首先，文件夹按topic+分区号命名规则，每个文件夹下有多个segment ，每个segment都有两个文件

.index索引文件 offset =>.log文件的起始位置（最小的偏移量） 文件每行数据大小固定

.log数据文件，存储大量的数据，会根据配置的大小做分片

两个文件名的命名规则都是按偏移量命名的

0000000000.index 0000000000.log

0000000099.index 0000000099.log

第一次定位 根据offset=3二分查找定位index文件，由于每条数据可以理解是固定的xx kb，所以直接定位到，再在.log文件根据偏移量+数据大小得到数据

### 数据可靠性 

例如3个副本 一个leader 两个follower

kafka生产者发送消息，就是可靠性保证发送到topic，topic的每个分区收到生产者的数据后，需要向生产者发送ack，生产者收到了，就会发送下一消息，否则重发

#### 中间产生的问题

1.什么时候发送ack

2.leader 跟 follower 多少个follower同步完成之后发送ack

#### 了解同步策略 才发送ack （同步是follower向leader发起同步请求）

1.半数以上同步完成 

优点：延迟低

缺点：2n+1个副本

2.全部同步

优点：n+1个副本

缺点：延迟高

#### 了解ISR 

kafka用的是全部同步策略发送ack，缺点就是延迟高，而且当同步follower的时候挂掉了一台，就一直不发送ack了，所以做了优化，动态ISR

ISR队列是预选举成leader的follower，当这些follower全部收到了就发送ack

#### 怎么动态维护ISR队列

如果 follower长时间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR， 该 时 间 阈 值 由**replica.lag.time.max.ms** 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。 

还有一个条数的参数设定，移除掉了

#### acks参数级别配置 （考虑到存在可以容忍数据丢失的，有些数据不是很重要，生产者没必要等待ISR的follower接收完成才发ack）

0：低延迟，不需要等待，生产者只管发数据，不等待broker写入磁盘，这种最容易丢失数据 

1：生产者只等待leader接收成功，返回ack，如果leader接收成功，写入磁盘，发送ack，但是此时follower还未向leader请求同步数据时，leader故障，也会丢失数据

-1（all）生产者等待leader接收成功，跟ISR的follower都请求同步数据，broker发送ack，极限情况，在follower完成同步，broker还未发送ack时，leader故障，就会收到生产者重发的数据，造成数据重复

#### 故障处理细节

Log文件的HW和LEO 

HW(High Watermark)

指的是消费者能见到的最大的** **offset****，****ISR** **队列中最小的** **LEO****。** 

LEO(Log End Offset)

LEO：指的是每个副本最大的offset；

![image-20210523184132313](G:\dev\typora-image\image-20210523184132313.png)



follower故障

follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘

记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。

等该 **follower** **的** **LEO** **大于等于该** **Partition** **的** **HW**，即 follower 追上 leader 之后，就可以重

新加入 ISR 了。

leader故障

leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。

注意：这只能保证副本之间的数据一致性（消费数据的一致性），并不能保证数据不丢失或者不重复。

### **Exactly Once**

这里提到幂等性 At Least Once（至少发送数据到分区一次以上） + 幂等性 = Exactly Once

是在acks=-1前提下，要保证数据不丢失，并解决数据不重复（这里肯定不是在消费者处理，多消费者怎么办呢？）

实现：Broker 端会对<PID, Partition, SeqNumber>做缓存，PID是生产者申请的代表ID，分区，跟消息发送的随机数

注意：但是当PID，就是生产者故障，重新申请PID，也避免不了

无法保证跨分区的跨会话的



# 生产故障

## 可靠性传输

### 消费端丢失了数据

唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢失了

就是将数据获取到了，维护在内存的Queue缓冲，还没来得及处理的数据就丢失了

解决：要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。

也会出现重复消费的情况：如果出现刚获取到消费数据，刚处理完，还没手动提交offset，服务挂掉了，重启也会重新消费，所以消费端也需要做自己的幂等性，比如入redis啥的

### kafka弄丢了数据

给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本。
在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧。
在producer端设置acks=all（-1）：这个是要求每条数据，必须是写入所有ISR的follower之后，brocker发送ack，才能认为是写成功了。
在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。坑

### 生产者会不会弄丢数据

如果按照上述的思路设置了ack=all（-1），一定不会丢，要求是，你的leader接收到消息，ISR所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

## 保证消息的顺序性

kafka：一个topic，一个partition，一个consumer，内部多线程，这不也明显乱了
　　如何来保证消息的顺序性呢？

解决：kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可。

## 如何解决消息队列的延时

### 大量消息在mq里积压了几个小时了还没解决

线上排障，consumer消费逻辑的问题，无法正常手动提交offset，当时积压的是商家账上余额的流水

几千万条数据在MQ里积压了七八个小时，从下午4点多，积压到了晚上很晚，10点多，11点多
这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复consumer的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。

一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条，1000多万条，所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来。

#### 临时紧急扩容了，具体操作步骤和思路如下：

先修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉。
新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量。
然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue。
接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据。
这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据。
等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息。



## 以及过期失效问题？

假设你用的是rabbitmq，**rabbitmq**是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq里，而是大量的数据会直接搞丢。

这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是**批量重导**，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。

这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。

假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次。

## 消息队列满了以后该怎么处理？

#### 消息队列满了怎么搞？ 如果走的方式是消息积压在mq里，那么如果你很长时间都没处理掉，此时导致mq都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

